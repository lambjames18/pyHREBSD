{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import utilities\n",
    "import GCC_Preprocess as gpp\n",
    "import pyHREBSD\n",
    "\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in data\n",
    "\n",
    "Data can be imported using the `utilities.get_scan_data` function. Note that this requires knowledge of the detector used during data collection. The detector pixel size (unbinned) and the detector pixel dimensions (unbinned) permit transforming the pattern center from (xstar, ystar, zstar) into (xpc, ypc, L).\n",
    "\n",
    "Note that this function does not actually read any patterns. To read in patterns, the function `utilities.get_patterns` must be called. This function also permits selection of a small region of interest within the scan by passing indices of the patterns of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the scan data and print out some information\n",
    "up2 = \"E:/cells/CoNi90-OrthoCells.up2\"\n",
    "ang = \"E:/cells/CoNi90-OrthoCells.ang\"\n",
    "pixel_size = 13.0\n",
    "Nxy = (2048, 2048)\n",
    "\n",
    "pat_obj, ang_data = utilities.get_scan_data(up2, ang, Nxy, pixel_size)\n",
    "print(\"Scan data loaded\")\n",
    "print(\"File size:\", pat_obj.filesize)\n",
    "print(\"Pattern shape:\", pat_obj.patshape)\n",
    "print(\"Number of patterns:\", pat_obj.nPatterns)\n",
    "print(\"Scan shape:\", ang_data.shape)\n",
    "print(\"Ang fields:\", ang_data.fields)\n",
    "\n",
    "# Grab a single pattern and display it\n",
    "pattern = utilities.get_patterns(pat_obj, [0])\n",
    "utilities.view(pattern, cmap='gray', title=\"1st pattern\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab a subset of the patterns\n",
    "point = (112, 96)\n",
    "size = 100\n",
    "\n",
    "idx = utilities.get_index(point, size, ang_data.shape)\n",
    "pats = utilities.get_patterns(pat_obj, idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pattern processing\n",
    "\n",
    "There are two recommended pattern processing routines.\n",
    "\n",
    "- **Applying a bandpass filter**: This is done using the difference of gaussians approach. This requires choosing a lower sigma that removes noise and a higher sigma that removes background intensity gradients.\n",
    "- **Apply adaptive histogram equalization**: This enhances the local contrast in the image to highlight bands.\n",
    "\n",
    "The `utilities.test_bandpass(pattern)` function will generate four composite images that allow you to tune the sigma values of the bandpass filter. It creates a grid of images with differen sigma values, the same with the histogram equalization applied, and the cross-correlation result of the images both with and without the histogram equalization.\n",
    "\n",
    "Once an optimal set of sigma values have been identified, the `utilities.process_patterns` function can be called.\n",
    "\n",
    "Similarly, the sharpness of the patterns can be caluclated using the `utilities.get_sharpness` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the bandpass test to determine what sigma values to use for the HREBSD analysis\n",
    "utilities.test_bandpass(pats[0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the patterns using the bandpass filter\n",
    "DoG_sigmas = (1.0, 10.0)\n",
    "pats_processed = utilities.clean_patterns(pats, equalize=True, dog_sigmas=DoG_sigmas)\n",
    "sharpness = utilities.get_sharpness(pats_processed)\n",
    "\n",
    "utilities.view(pats[0, :3])\n",
    "utilities.view(sharpness)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running HREBSD\n",
    "\n",
    "With the patterns processed, we can now run HREBSD. The first step is to define the reference pattern of the image and the subset size to use.\n",
    "\n",
    "With the reference and subset, we first calculate the initial guesses of the homographies in order to speed up the actual HREBSD analysis. This is done with `gpp.GCC_Initial_Guess`. Note that this function takes time.\n",
    "\n",
    "Once the initial guesses have been made, we can run HREBSD to get the actual homographies. Homographies are then used to determine the deviatoric deformation gradient tensor and the strain/rotation tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the reference pattern and the subset slice to use for the HREBSD analysis\n",
    "R = pats[112, 96]\n",
    "subset_slice = (slice(R.shape[0] // 2 - 64, R.shape[0] // 2 + 64),\n",
    "                slice(R.shape[1] // 2 - 64, R.shape[1] // 2 + 64))\n",
    "\n",
    "# Also set a save_name for the results\n",
    "save_name = \"CoNi90-OrthoCells_R112-96\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the initial guesses for the HREBSD analysis\n",
    "p0 = gpp.GCC_Initial_Guess(R, pats)\n",
    "np.save(f\"{save_name}_p0.npy\", p0)\n",
    "# p0 = np.load(f\"{save_name}_p0.npy\", p0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the HREBSD analysis using the initial guesses\n",
    "p = pyHREBSD.get_homography(R, pats, subset_slice=subset_slice, p0=p0, max_iter=50, conv_tol=1e-7)\n",
    "np.save(f\"{save_name}_p.npy\", p)\n",
    "# p = np.load(f\"{save_name}_p.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the deviatoric deformation gradient tensor\n",
    "Fe = pyHREBSD.homography_to_elastic_deformation(p, ang_data.pc)\n",
    "\n",
    "# Calculate the strain tensor and the rotation tensor\n",
    "e, w = pyHREBSD.deformation_to_strain(Fe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save out the results\n",
    "xy = (50, 50) # The location of the reference point\n",
    "\n",
    "plt.close('all')\n",
    "utilities.view_tensor_images(Fe, tensor_type=\"deformation\", xy=xy, save_name=save_name, save_dir=\"results/\")\n",
    "utilities.view_tensor_images(e, tensor_type=\"strain\", xy=xy, save_name=save_name, save_dir=\"results/\")\n",
    "utilities.view_tensor_images(w, tensor_type=\"rotation\", xy=xy, save_name=save_name, save_dir=\"results/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3D",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
